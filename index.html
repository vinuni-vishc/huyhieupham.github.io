<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
	  
    
    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <title>Hieu Pham</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Hieu Pham</name>
              </p>
              <p> I am currently an Assistant Professor of Computer Science at <a href="https://vinuni.edu.vn/">VinUniversity</a> where I work on Computer Vision, Machine Learning, Artificial Intelligence (AI) and Smart Health Applications. I received my Ph.D. degree in Computer Science at the <a href="https://www.irit.fr/?lang=en">Toulouse Computer Science Research Institute (IRIT)</a> - <a href="https://en.univ-toulouse.fr/">The University of Toulouse</a>, France in 2019. I joined the <a href="https://csl.illinois.edu/">Coordinated Science Laboratory</a> at <a href="https://illinois.edu/">University of Illinois Urbana-Champaign (UIUC)</a>, USA as a Visiting Scholar in 2023.
              </p>
              <p>
                I spent two years as a Research Scientist at <a href="https://vinbigdata.com/en/">Vingroup Big Data Institute</a> where I conducted research on Medical Imaging Analysis and was leading several research projects on AI in Medicine, including the collection of various types of medical data, managing and annotating data, and developing new AI solutions for detecting and classifying diseases from medical imaging data (<a href="https://vindr.ai/">https://vindr.ai/</a>). In 2015, I spent half a year at the <a href="http://institut-clement-ader.org/">ICA laboratory</a>, <a href="https://www.imt-mines-albi.fr/">École des Mines d'Albi</a> for working on a dynamic multi-partner robotized airplane inspection project, called <a href="https://www.youtube.com/watch?v=YLikbi48yEg">Air-Cobot</a>, lead by <a href="https://www.akka-technologies.com/fr">AKKA Technologies</a> and <a href="AIRBUS group">AIRBUS group</a>.
              </p>
			  
	      <p>
	      Previously, I did my bachelors at the <a href="https://en.hust.edu.vn/">Hanoi University of Science and Technology (HUST)</a>. <a href="https://www.youtube.com/watch?v=9IQPptJbO4M">My graduate internship</a> was done at <a href="https://www.mica.edu.vn/">International Research Institute MICA</a>, Hanoi, Vietnam et <a href="http://www.grenoblecognition.fr/index.php/le-pole/unites-contituantes/57-les-unites/172-agim-andrologie-gerontologie-inflammation-modelisation"> AGIM laboratory</a>, <a href="https://www.univ-grenoble-alpes.fr/english/">Université Grenoble Alpes</a>, Grenoble, France.
		      
	      </p>  
			  
              <p align=center>
		<a href="data/Huy_Hieu_PHAM_Doctoral_Thesis.pdf">Ph.D. Thesis</a> &nbsp/&nbsp
                <a href="data/Hieu_Pham.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=mXcFcNkAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
		<a href="https://github.com/huyhieupham/">GitHub</a> &nbsp/&nbsp
		<a href="https://www.linkedin.com/in/hieu-pham-25615236/">LinkedIn</a> 
              </p>
            </td>
            <td width="33%">
              <img src="images/huyhieupham_2_320x350.png">
            </td>
          </tr>
		
         </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research Interests</heading>
              <p>
                My research interests include Artificial Intelligence (AI), Machine Learning, Deep Learning, Computer Vision, especially their applications in Smart Healthcare, e.g. Medical Imaging Diagnosis, AI-based Computer-aided Diagnosis (AI-CAD), AI-assisted Diagnosis and Treatment, AI-assisted Disease Prevention and Risk Monitoring. Check my latest publications <a href="https://scholar.google.com/citations?user=mXcFcNkAAAAJ&hl=en">here</a>.

            </p>    
		    
		    <p style="color:red">I am looking for self-motivated PhD, Research Assisstants and Interns, who are interested in artificial intelligence for smart healthcare, computer vision, machine/deeep learning, and natural language processing. If you are interested in doing research with me, please send me an email (hieu.ph@vinuni.edu.) with your CV and transcripts. If you are a VinUni student and interested in conducting research, you can reach me via email for further dicussion. Remote collaboration is also welcome!</p>

		   
		  </td>
          </tr>
	 </table>
	      
	  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>News</heading>
		    <p>
		    
		    <span>&#x25cf;</span> &nbsp; <b>[May 2023]</b> &nbsp; Our international research team (VinUniversity, L'Université Grenoble Alpes and Instituto Nacional de Telecomunicações) won 500,000 EURO funding from the Multidisciplinary Institute in Artificial Intelligenceto (France) to develop our interdisciplinary project "Smart Life Smart Living Intercontinental. AI by and for People".
		    </p>
		    
		    <p>
			     
		    <span>&#x25cf;</span> &nbsp; <b>[May 2023]</b> &nbsp; Our paper titled "<a href="https://arxiv.org/pdf/2302.10413.pdf">CADIS: Handling Cluster-skewed Non-IID Data in Federated Learning with Clustered Aggregation and Knowledge DIStilled Regularization</a>" won the Best Paper Award (ML Track) at The 23rd IEEE/ACM international Symposium on Cluster, Cloud and Internet Computing (CCGrid 2023).
		    </p> 
		    
		    
		     <p>
			     
		    <span>&#x25cf;</span> &nbsp; <b>[May 2023]</b> &nbsp; We run our <a href="data/ai-in-medicine.pdf">AI in Medicine Seminar</a>.
		    </p> 
		    
		     <p>
		    
		  <span>&#x25cf;</span> &nbsp; <b>[Mar. 2023]</b> &nbsp; Two papers got accepted for publication in <a href="https://www.nature.com/sdata/">Nature Scienfic Data (IF 11.211)</a>. Check out preprints <a href="https://arxiv.org/pdf/2203.11205.pdf">here</a> and <a href="https://arxiv.org/pdf/2203.10612.pdf"> here</a>.
		  	</p>  
		    
		
		    <p>
		    
		  <span>&#x25cf;</span> &nbsp; <b>[Mar. 2023]</b> &nbsp; I have joined <a href="https://csl.illinois.edu/">Coordinated Science Laboratory, UIUC</a> as a Visiting Scholar, working on AI in Medicine with my Advisor, Prof. <a href="https://scholar.google.com/citations?user=RIeAomMAAAAJ&hl=en">Minh Do</a>.
		  	</p> 
		    
		    
		     <p>
		    
		  <span>&#x25cf;</span> &nbsp; <b>[Jan. 2023]</b> &nbsp; Our VinUni-UIUC research team (with Stephen Boppart, Mark A Anastasio, Marina Marjanovic, Mai Tran, Nhung Nguyen, and Wray Buntine) got $260K funding from VISHC Research Funding Program to work on the Evaluation of the Effect of Antiviral Drugs using Polarized Light Imaging. We are looking for 5 PhDs and 1 Postdoc to join us. See more <a href="https://smarthealth.vinuni.edu.vn/?careers=ph-d-call-for-applications-at-vinuni-and-the-university-of-illinois-on-evaluating-the-effect-of-antiviral-drugs-using-polarized-light-imaging-and-machine-learning-approaches-the-case-of-human-induce">here</a>. 
		  	</p> 
		    
		    
		 <p>
		    
		  <span>&#x25cf;</span> &nbsp; <b>[Jan. 2023]</b> &nbsp; Three papers got accepted (2xQ1 Journals and 1-rank A conference). Congratulations to all authors and co-authors!
		  	</p> 
		       
		    
		    
		  <p>
		    
		  <span>&#x25cf;</span> &nbsp; <b>[Nov. 2022]</b> &nbsp;   In the last three months, 10 research articles got accepted or provisionally accepted for publication at top journals and conferences in AI and Medicine, including PLOS One, Computers in Biology and Medicine, ACCV, and ICPP. A complete list of publications is available <a href="https://smarthealth.vinuni.edu.vn/publications/">here</a>. Congratulations to all authors and co-authors. 
		  	</p> 
		    
		    
		      <p>
		    
		  <span>&#x25cf;</span> &nbsp; <b>[Oct. 2022]</b> &nbsp;  Got promoted to Assistant Professor in Computer Science at the College of Engineering & Computer Science, VinUniversity.
				
		  	</p> 
		    
		   <p>
		    
		  <span>&#x25cf;</span> &nbsp; <b>[Sep. 2022]</b> &nbsp;  We win <a href="https://vnexpress.net/he-thong-phat-hien-uong-thuoc-sai-don-thang-giai-ai-awards-2022-4513567.html">AI Awards 2022</a>.
				
		  	</p> 
		    
			<p>
		    
		  <span>&#x25cf;</span> &nbsp; <b>[Sep. 2022]</b> &nbsp;  Take a short-term visit to the German Center for Neurodegenerative Diseases (<a href="https://www.dzne.de/">DZNE</a>), Bonn, and the German Research Center for Artificial Intelligence (<a href="DFKI">DFKI</a>), in order to explore new space for collaboration with <a href="https://www.dzne.de/forschung/forschungsbereiche/populationsforschung/forschungsgruppen/reuter/forschungsschwerpunkte/"> Prof. Martin Reuter</a> (Head of Image Analysis, DZNE; Assistant Professor of Radiology, Harvard Medical School) and <a href="https://www.isip.uni-luebeck.de/index.php?id=278"> Prof. Alfred Mertins</a> (Director of the Institute for Signal Processing, University of Lübeck). 
				
		  	</p>  
		    	    
		    
		    
		    
			<p>
		    
		  <span>&#x25cf;</span> &nbsp; <b>[Aug. 2022]</b> &nbsp;  I am looking for a PhD student working on <a href="https://smarthealth.vinuni.edu.vn/?careers=phd-studentship-ai-based-medical-image-analysis-for-early-detection-and-diagnosis"> AI-based Medical Image Analysis for Early Detection and Diagnosis </a>. This thesis shall be supervised by me, 
				Prof. <a href= "https://profiles.uts.edu.au/Qiang.Wu"> Qiang Wu</a>, and Prof. <a href="https://profiles.uts.edu.au/Min.Xu"> Min Xu</a> from <a href="https://www.uts.edu.au/"> University of Technology Sydney (UTS)</a>. Selected candidate will be provided full scholarships to conduct her/his research at VinUniversiy and UTS. 
		  	</p>  
		    
		    
		    
		    
		    
		    
		    
			<p>
		    
		  <span>&#x25cf;</span> &nbsp; <b>[Jul. 2022]</b> &nbsp;  I serve as a Program Committee (PC) Member for the <a href="https://aaai.org/Conferences/AAAI-23/"> Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI-23) </a>.
		  	</p>  
		    
			    
		   <p>
			<span>&#x25cf;</span> &nbsp; <b>[Jul. 2022]</b> &nbsp; Our paper "Deployment and validation of an AI system for detecting abnormal chest radiographs in clinical settings" is accepted by <a href="https://www.frontiersin.org/articles/10.3389/fdgth.2022.890759/full?&utm_source=Email_to_authors_&utm_medium=Email&utm_content=T1_11.5e1_author&utm_campaign=Email_publication&field=&journalName=Frontiers_in_Digital_Health&id=890759">Frontiers in Digital Health</a>.
		    	</p>      
		    
		    
		    
		   <p>
			<span>&#x25cf;</span> &nbsp; <b>[Jul. 2022]</b> &nbsp; Our paper "VinDr-CXR: An open dataset of chest X-rays with radiologist’s annotations" is accepted by <a href="https://www.nature.com/articles/s41597-022-01498-w?fbclid=IwAR0l1C6mFmV8v4Cq7tJFpqxGw1LH_eXrGnhi1AQ8mXucXCSkZkALVWXA4u4">Scientific Data (Nature, IF 9.051)</a>.
		    	</p>  
		    
		    
		     <p>
			<span>&#x25cf;</span> &nbsp; <b>[Jul. 2022]</b> &nbsp; <a href="https://smarthealth.vinuni.edu.vn/">VinUni-Illinois Smart Health Center (VISHC)</a> is officially launched. With 13,5 million USD in funding from Vingroup, VISHC will focus on interdisciplinary research in biotechnology and data science to develop affordable and accessible projects that can positively impact people’s health.	    
		    
		    	</p>  
		    
		 
		    
		    
		    
		    <p>
		    <span>&#x25cf;</span> &nbsp; <b>[Feb. 2022]</b> &nbsp; I serve as a Reviewer for European Conference on Computer Vision 2022 (<a href="https://eccv2022.ecva.net/">ECCV2022</a>) and the 25th International Conference on Medical Image
Computing and Computer Assisted Intervention (<a href="https://conferences.miccai.org/2022/en/">MICCAI2022</a>)
		    </p>
		    
		    <p>
			<span>&#x25cf;</span> &nbsp; <b>[Dec. 2021]</b> &nbsp; Our research team got $220K funding from <a href="https://vinif.org/">Vingroup Innovation Foundation - VinIF</a> to enhance medication safety. 
		    	</p>
		    
			<p>
			<span>&#x25cf;</span> &nbsp; <b>[Nov. 2021]</b> &nbsp; I gave a talk on <a href="/data/Explainable AI How human can trust AI - Hieu Pham VinUni.pdf">Explainablle AI</a>  at  <a href="https://ainow.bkai.ai/">AI Now: Research and Development</a> 2021 conference, organized by BK.AI (HUST) and Naver Corporation. 
		    	</p>
		    
			<p>
			<span>&#x25cf;</span> &nbsp; <b>[Nov. 2021]</b> &nbsp; I join VinUni as a Teaching Fellow at the College of Engineering and Computer Science and Research Fellow at VinUni-Illinois Smart Health Center (VISHC).
		    	</p>
		    <p>
			<span>&#x25cf;</span> &nbsp; <b>[Sep. 2021]</b> &nbsp; I serve as a reviewer for <a href="http://cvpr2022.thecvf.com/">IEEE/CVF Conference on Computer Vision and Pattern Recognition 2022 (CVPR2022)</a>.
		    </p>
		      
		    <p>
			<span>&#x25cf;</span> &nbsp; <b>[Aug. 2021]</b> &nbsp; We release VinDr-SpineXR: <a href="https://vindr.ai/datasets/spinexr">An open dataset for spinal lesions detection and classification from radiographs</a> on <a href="https://www.physionet.org/content/vindr-spinexr/1.0.0/">PhysioNet</a>. To the best of our knowledge, the VinDr-SpineXR is currently the largest dataset to date that provides radiologist’s bounding-box annotations for developing supervised-learning object detection algorithms. We believe that the dataset will serve as a benchmark dataset for accelerating the development and evaluation of new machine learning models for the spinal X-ray interpretation.
		    </p>
		    
		    
		    <p>
			<span>&#x25cf;</span> &nbsp; <b>[Aug. 2021]</b> &nbsp; Two papers got accepted by <a href="https://sites.google.com/view/CVAMD2021/">ICCV Workshop 2021 on Computer Vision for Automated Medical Diagnosis</a>.
		    </p>		    
		    
		    
			<p>
			<span>&#x25cf;</span> &nbsp; <b>[June 2021]</b> &nbsp; One paper on "<a href="https://arxiv.org/pdf/2106.12930.pdf">A deep learning framework for spinal lesions detection and classification from radiographs</a>" got accepted by <a href="https://miccai2021.org/en/">International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2021)</a>.
		  	</p>		    
		    
		    
		    
		    <p>
			<span>&#x25cf;</span> &nbsp; <b>[May 2021]</b> &nbsp; Our new paper titled "<a href="https://openreview.net/pdf?id=oJi6xpSLdsj"> VinDr-RibCXR: A Benchmark Dataset for Automatic Segmentation and Labeling of Individual Ribs on Chest X-rays"</a> is accepted by <a href="https://2021.midl.io/">Medical Imaging with Deep Learning (MIDL 2021)</a>.
		    </p>
		    
		<p>
			<span>&#x25cf;</span> &nbsp; <b>[Apr. 2021]</b> &nbsp; I gave a talk on <a href="data/DS&AI-AI-in-Medical-Imaging-Hieu-Pham-VinBigdata.pdf">AI in Medical Imaging</a> at the <a href="https://soict.hust.edu.vn/summer-school/?fbclid=IwAR1-JJfbeaWVYmyE1kr9dBrqtkttpymNSk5OiKiWCzDbSBo_eZWhPr5vyzA">Summer School on Advances in DS&AI 2021 </a>.
		    </p>

		    
		    		<p>
			<span>&#x25cf;</span> &nbsp; <b>[Apr. 2021]</b> &nbsp; A new paper on AI for chest X-ray analysis is published on <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231221000953">Neurocomcomputing</a>.
		    </p>
		    
		 
		
		<p>
			<span>&#x25cf;</span> &nbsp; <b>[Feb. 2021]</b> &nbsp; I serve as a Reviewer for International Conference on Computer Vision (ICCV2021).
		    </p>
		    
		 
		    
		<p>    
		   <span>&#x25cf;</span> &nbsp; <b>[Sep. 2019]</b> &nbsp;  I just successfully defended my <a href="data/Huy_Hieu_PHAM_Doctoral_Thesis.pdf">Ph.D. thesis</a> at the Computer Science Research Institute of Toulouse (IRIT), France. The presentation is available <a href="data/PhD_Presentation_Final_Version_Hieu_Pham.pdf">here</a>. I will back to Hanoi, Vietnam and work as a Research Scientist in Computer Vision and Artificial Intelligence (AI) at the Vingroup Big Data Institute (VinBDI) starting from October 2019. My work focuses on applying the latest advances in Machine Learning & Deep Learning for Medical Imaging Analysis.
		</p>    
		    	    
		    
		<p>    
		   <span>&#x25cf;</span> &nbsp; <b>[July 2019]</b> &nbsp; In our recent study, we showed that a simple deep neural network is able to learn and predict 3D human poses from 2D keypoints obtained from RGB images. The full paper about this research is available on <a href="https://arxiv.org/pdf/1907.06968v1.pdf">arXiv</a>.   
		</p> 
	
		<p>    
		   <span>&#x25cf;</span> &nbsp; <b>[July 2019]</b> &nbsp;  I gave a <a href="data/Poster_SI_IRIT_17_July_2019.pdf">poster presentation</a> at the annual seminar of Toulouse Computer Science Research Institute (IRIT), France. The presentation was about training a deep learning neural network for predicting 3D human poses from their 2D keypoint detections on RGB images.   
		</p>
	    
		    	       
            
		<p> 
			<span>&#x25cf;</span> &nbsp; <b>[July 2018]</b> &nbsp; My new paper about improving ResNet architecture for human action recognition (HAR) with RGB-D data has been accepted with revision for publication by the <a href="http://digital-library.theiet.org/content/journals/iet-cvi"> IET Computer Vision Journal</a>.
			</p>
		 <p>
		<span>&#x25cf;</span> &nbsp; <b>[May 2018]</b> &nbsp; My paper titled: "Exploiting Inception-ResNet networks for human action recognition (HAR) from skeletal data" has been accepted for oral presentation at the <a href="https://2018.ieeeicip.org/">25th IEEE International Conference on Image Processing (ICIP 2018)</a>.
		</p>
		<p>
		<span>&#x25cf;</span> &nbsp; <b>[Jun. 2018 ]</b> &nbsp; My paper: "Exploiting deep residual networks for human action recognition from skeletal data" has been accepted for publication in the <a href="https://www.sciencedirect.com/science/article/pii/S1077314218300389"> Computer Vision and Image Understanding Journal</a>.
		</p> 
		    
            </td>
          </tr>
        </table>
	      
	      
	      
	 
	<table width="95%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
		  <heading> &nbsp; &nbsp; Publications</heading>  
		  
		  
		  
		  
		  
		  
	<tr onmouseout="loss_stop()" onmouseover="loss_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='loss_image'><img src='images/IET_2018.png'></div>
                <img src='images/IET_2018.png'>
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }
                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>		    
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://digital-library.theiet.org/content/journals/10.1049/iet-cvi.2018.5014">
                <papertitle>Learning to Recognize 3D Human Action from A New Skeleton-based Representation Using Deep Convolutional Neural Networks</papertitle>
              </a>
	      <br> 
	      <font color="red"><strong>Journal Paper</strong></font>    
              <br>
              <strong>Huy Hieu Pham</strong>, 
	      <a href="https://www.researchgate.net/profile/Louahdi_Khoudour">Louahdi Khoudour</a>,
	      <a href="https://www.irit.fr/~Alain.Crouzil/">Alain Crouzil</a>,
	      <a href="https://www.researchgate.net/profile/Pablo_Zegers">Pablo Zegers</a>, and
	      <a href="https://www.uc3m.es/ss/Satellite/UC3MInstitucional/en/FormularioTextoDosColumnas/1371216239282/Very_experienced_fellow">Sergio A Velastin</a>
              <br>
              <em>IET Computer Vision</em>, IET 2018
              <br>
              <a href="https://arxiv.org/pdf/1812.10550.pdf">arXiv</a> /
	      <a href="https://doi.org/10.1049/iet-cvi.2018.5014">DOI</a> /    
              <a href="data/HieuPham_IET_2018.bib">BibTeX</a>
              <p></p>
              <p>Transforming 3D joint coordinates of the human body carried in skeleton sequences into RGB images for human action recognition in videos with deep neural networks.</p>
            </td>
          </tr>
	  </tr>
        </table>  
	  
	<table width="95%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
	<tr onmouseout="loss_stop()" onmouseover="loss_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='loss_image'><img src='images/ICIP_2018.png'></div>
                <img src='images/ICIP_2018.png'>
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }
                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>		    
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8451404">
                <papertitle>Skeletal Movement to Color Map: A Novel Representation for 3D Action Recognition with Inception Residual Networks</papertitle>
              </a>
	      <br> 
	      <font color="red"><strong>Conference Paper</strong></font>    
              <br>
              <strong>Huy Hieu Pham</strong>, 
	      <a href="https://www.researchgate.net/profile/Louahdi_Khoudour">Louahdi Khoudour</a>,
	      <a href="https://www.irit.fr/~Alain.Crouzil/">Alain Crouzil</a>,
	      <a href="https://www.researchgate.net/profile/Pablo_Zegers">Pablo Zegers</a>, and
	      <a href="https://www.uc3m.es/ss/Satellite/UC3MInstitucional/en/FormularioTextoDosColumnas/1371216239282/Very_experienced_fellow">Sergio A Velastin</a>
              <br>
              <em>The 25th IEEE International Conference on Image Processing</em>, ICIP2018, October 7-10, 2018, Athens, Greece
              <br>
              <a href="https://arxiv.org/pdf/1807.07033.pdf">arXiv</a> /
	      <a href="https://doi.org/10.1109/ICIP.2018.8451404">DOI</a> /    
              <a href="data/HieuPham_ICIP_2018.bib">BibTeX</a>
	      <p></p>
              <p>Proposing a new 3D skeleton-based representation, namely, SPMF (Skeleton Pose-Motion Feature) for video-based human action recogntion with depth sensors.</p>
            </td>
          </tr>
	  </tr>
        </table>  
		  
	<table width="95%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
	<tr onmouseout="loss_stop()" onmouseover="loss_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='loss_image'><img src='images/CVIU_figure.png'></div>
                <img src='images/CVIU_figure.png'>
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }
                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>		    
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.sciencedirect.com/science/article/pii/S1077314218300389">
                <papertitle>Exploiting Deep Residual Networks for Human Action Recognition from Skeletal Data</papertitle>
              </a>
	      <br> 
	      <font color="red"><strong>Journal Paper</strong></font>    
              <br>
              <strong>Huy Hieu Pham</strong>, 
	      <a href="https://www.researchgate.net/profile/Louahdi_Khoudour">Louahdi Khoudour</a>,
	      <a href="https://www.irit.fr/~Alain.Crouzil/">Alain Crouzil</a>,
	      <a href="https://www.researchgate.net/profile/Pablo_Zegers">Pablo Zegers</a>, and
	      <a href="https://www.uc3m.es/ss/Satellite/UC3MInstitucional/en/FormularioTextoDosColumnas/1371216239282/Very_experienced_fellow">Sergio A Velastin</a>
              <br>
              <em>Computer Vision and Image Understanding</em>, CVIU 2018
              <br>
              <a href="https://arxiv.org/pdf/1803.07781.pdf">arXiv</a> /
	      <a href="https://doi.org/10.1016/j.cviu.2018.03.003">DOI</a> /    
	      <a href="https://github.com/huyhieupham/Improved-ResNet-Action-Recognition-Skeletal-Data">Code</a> /
              <a href="data/HieuPham_CVIU_2018.bib">BibTeX</a>
	      <p></p>
              <p>Investigating and applying deep ResNets for human action recognition using skeletal data provided by depth sensors.</p>
            </td>
          </tr>
	  </tr>
        </table>  
		  
	<table width="95%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
	<tr onmouseout="loss_stop()" onmouseover="loss_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='loss_image'><img src='images/DefautJENv1.png'></div>
                <img src='images/DefautJENv1.png'>
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }
                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>		    
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/article/10.1007/s10921-017-0453-1">
                <papertitle>3D Point Cloud Analysis for Detection and Characterization of Defects on Airplane Exterior Surface</papertitle>
              </a>
	      <br> 
	      <font color="red"><strong>Journal Paper</strong></font>    
              <br>
              Igor Jovančević, <strong>Huy Hieu Pham</strong>, Jean-José Orteu, Rémi Gilblas, Jacques Harvent, Xavier Maurice, and Ludovic Brèthes
              <br>
              <em>Journal of Nondestructive Evaluation</em>, JNE 2017
              <br>
              <a href="https://hal-mines-albi.archives-ouvertes.fr/hal-01622056/document">Full-text PDF</a> /
	      <a href="https://doi.org/10.1007/s10921-017-0453-1">DOI</a> /    
              <a href="data/Jovancevic2017JNE.bib">BibTeX</a>
              <p></p>
              <p>A novel automatic vision-based inspection system that is capable of detecting and characterizing defects on an airplane exterior surface.</p>
            </td>
          </tr>
	  </tr>
        </table>  
		
	<table width="95%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr> 	  
	   <tr onmouseout="loss_stop()" onmouseover="loss_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='loss_image'><img src='images/Nuage.png'></div>
                <img src='images/Nuage.png'>
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }
                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>		    
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://hal.archives-ouvertes.fr/hal-01660998/">
                <papertitle>Détection et Caractérisation de Défauts de Surface par Analyse des Nuages de Points 3D Fournis par un Scanner</papertitle>
              </a>
	      <br> 
	      <font color="red"><strong>Journal Paper</strong></font>    
              <br>
              Igor Jovančević, <strong>Huy Hieu Pham</strong>, Jean-José Orteu, Rémi Gilblas, Jacques Harvent, Xavier Maurice, and Ludovic Brèthes
              <br>
              <em>Journal of Sensors</em>, 2016
              <br>
              <a href="https://hal.archives-ouvertes.fr/hal-01660998/document">Full-text PDF</a> /
              <a href="data/jovancevic:hal2017.bib">BibTeX</a>
              <p></p>
              <p>A system that is able to detect obstacles in indoor environment based on Kinect sensor and 3D-image processing.</p>
            </td>
          </tr>
	  </tr>
        </table>

		
						   
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Teaching</heading>
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Instructor</b>, College of Engineering & Computer Science (CECS), VinUniversity. <br>
				&nbsp; &nbsp; &nbsp; <b> Course:</b> <i> "Introduction to Programing - CECS-COMP1010 (Fall 2021-2022)"</i>, with Prof. <a href="https://vinuni.edu.vn/people/kok-seng-wong/">Kok-Seng Wong</a>
		</p>					    
				
					    
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Instructor</b>, College of Engineering & Computer Science (CECS), VinUniversity. <br>
				&nbsp; &nbsp; &nbsp; <b> Course:</b> <i> "Introduction to Machine Learning - CECS-1020 (Spring 2021-2022)"</i>, with Prof. <a href="https://vinuni.edu.vn/people/minh-do/">Minh Do</a>
		</p>					    
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Guest Lecturer</b>, University Carlos III of Madrid, Spain. <br>
		                  &nbsp; &nbsp; &nbsp;  <b> Course:</b> 	<i>"An introduction to Deep Learning for Image and Video Interpretation"</i>, (Fall 2017-2018).
		</p>						    
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Teaching Assistant</b>, University of Toulouse, France. <br>
					&nbsp; &nbsp; &nbsp;  <b> Course:</b> <i> "Introduction to Programming and Algorithms in Python"</i>, (Fall 2018-2019).															
		</p>						    
            </td>
          </tr>
	 </table>						   
						   
		<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Former Graduate Students</heading>
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Tung T. Le</b> (co-supervise with Dr. Ha Q. Nguyen), now CS Ph.D. student @ University of California Irvine.<br>
				
		</p>					    
				
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Hieu T. Nguyen</b> (co-supervise with Dr. Ha Q. Nguyen), now CS Ph.D. student @ Northeastern University.<br>
				
		</p>	
					    
					    <p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Thao Nguyen</b>, incoming CS Ph.D. student @ The University of Illinois Urbana-Champaign (UIUC).<br>
				
		</p>	
					    
					    <p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Tuan M. Nguyen</b>, now CS Ph.D. student @ VinUniversity.<br>
				
		</p>	
					 
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Quan M. Nguyen</b>, now Msc. Biomedical Computing at Department of Informatics, TU Munich.<br>		
		</p>
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Huyen Nguyen</b>, now MSc student @ Tokyo University of Agriculture and Technology.<br>
				
		</p>	
			
		 <p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Sam Sam</b>, now Applied Scientist @ VinBrain.<br>
				
		</p>
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Thanh Tran</b>, now AI Research Engineer @ VinBigData<br>
				
		</p>
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Dung V. Do</b>, now AI Research Engineer @ VinBrain<br>		
		</p>
		
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Hoang C. Nguyen</b> (Gold IMO 2017), now undergrad @ KAIST and incoming RA @ VinUni-Illinois Smart Health Center.<br>		
		</p>	
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Tung T. Nguyen</b>, now RA @ VinUniversity.<br>		
		</p>
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Tuan Tran</b>, now RA @ VinUni-Illinois Smart Health Center.<br>		
		</p>	
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Khiem Le</b>, now RA @ VinUni-Illinois Smart Health Center.<br>		
		</p>			    
					    
            </td>
          </tr>
	 </table>			   
						   
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Professional Activities</heading>
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>,  Medical Image Computing and Computer-Assisted Intervention 2023 (<a href="https://conferences.miccai.org/2023/en/">MICCAI 2023</a>).
		</p>	
		
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>,  The ACM Transactions on Multimedia Computing Communications and Applications (<a href="https://dl.acm.org/journal/tomm">TOMM</a>).
		</p>				    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>,  The International Conference on Information Processing in Computer-Assisted Interventions (<a href="https://www.ipcai.org/">IPCAI 2023</a>).
		</p>
		
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>,  IEEE/CVF Conference on Computer Vision and Pattern Recognition 2023 (<a href="https://cvpr2023.thecvf.com/">CVPR 2023</a>)
		</p>
		
		
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Visiting Scholar</b>,  German Research Center for Artificial Intelligence (<a href="https://www.dfki.de/web">DFKI</a>), University of Lübeck, Germany, 2022.
		</p>
					 
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Visiting Scholar</b>,  German Center for Neurodegenerative Diseases (<a href="https://www.dzne.de/">DZNE</a>), Germany, 2022.
		</p>
	
				    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>,  IEEE International Conference on Knowledge and Systems Engineering (<a href="https://kse2022.tbd.edu.vn/">IEEE KSE 2022</a>).
		</p>
		
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>,  IEEE Journal of Selected Topics in Signal Processing (<a href="https://signalprocessingsociety.org/publications-resources/ieee-journal-selected-topics-signal-processing/about-jstsp">JSTSP</a>).
		</p>
					
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>,  European Conference on Computer Vision (<a href="https://eccv2022.ecva.net/">ECCV 2022</a>). 
		</p>
					    				    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>,  International Conference on Medical Image Computing and Computer Assisted Intervention (<a href="https://conferences.miccai.org/2022/en/">MICCAI 2022</a>). 
		</p>
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>, IEEE Journal of Biomedical and Health Informatics (<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221020">JBHI</a>). 
		</p>
					    
					    
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>, Journal of Electronic Imaging (<a href="https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging?SSO=1">JEI</a>). 
		</p>					    
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>, IET Computer Vision Journal (<a href="https://digital-library.theiet.org/content/journals/iet-cvi">IET-CVI</a>).
		</p>						    
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>, International Conference on Computer Vision (<a href="http://iccv2021.thecvf.com/home">ICCV 2021</a>).
		</p>
			
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>, IEEE/CVF Conference on Computer Vision and Pattern Recognition 2022 (<a href="https://cvpr2022.thecvf.com/">CVPR2022</a>). 
		</p>			

		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>, Nature <a href="https://www.nature.com/srep/">Scientific Reports</a>.
		</p>
		
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Program Commitee</b>, International Conference on Multimedia Analysis and Pattern Recognition (<a href="https://mapr.uit.edu.vn/program-committee">MAPR</a>).	   
		</p>
					    
					    			    
					    
					    
            </td>
          </tr>
	 </table>					   
						   
					    
					    
					   			    
					    
        </table>
	      
        <table width="100%" align="center" border="0" cellpadding="20"> 
	
            
              <p>
                
                <br>
                <br>
                
                <br>
                <br>
              </p>
            </td>
        
								      

								      
							      
								      
								      
								      
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
                  Thanks <a href="https://jonbarron.info/">Jon Barron</a> for his awesome open source code.
       
                  </font>
              </p>
            </td>
          </tr>
        </table>	
	      

		
        
         <!–– Please delete this script if you use this HTML. ––>
        <script type="text/javascript">
          var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
        </script>
        <script type="text/javascript">
          try {
            var pageTracker = _gat._getTracker("UA-7580334-1");
            pageTracker._trackPageview();
          } catch (err) {}
        </script>
        </td>
    </tr> 
  </table>
</body>
</html>		
							     
				     
							     
