<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
	  
    
    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <title>Huy Hieu Pham</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Huy Hieu Pham</name>
              </p>
              <p> I am a Research and Teaching Fellow at <a href="https://vinuni.edu.vn/">VinUniversity</a> where I work on Computer Vision, Machine Learning, Artificial Intelligence (AI) and Smart Health. I received my Ph.D. degree in Computer Science at the <a href="https://www.irit.fr/?lang=en">Toulouse Computer Science Research Institute (IRIT)</a> and <a href="https://www.cerema.fr/fr">Toulouse Cerema Research Center</a>, France in 2019.
              </p>
              <p>
                I spent two years as a Research Scientist at Vingroup Big Data Institute (<a href="https://vinbigdata.com/en/">VinBigdata</a>) where I conducted research on Medical Imaging Analysis and was leading several research projects on Medical AI, including the collection of various types of medical data, managing and annotating data, and developing new AI solutions for detecting and classifying diseases from medical imaging data (<a href="https://vindr.ai/">https://vindr.ai/</a>). In 2015, I spent half a year at the <a href="http://institut-clement-ader.org/">ICA laboratory</a>, <a href="https://www.imt-mines-albi.fr/">École des Mines d'Albi</a> for working on a dynamic multi-partner robotized airplane inspection project, called <a href="https://www.youtube.com/watch?v=YLikbi48yEg">Air-Cobot</a>, lead by <a href="https://www.akka-technologies.com/fr">AKKA Technologies</a> and <a href="AIRBUS group">AIRBUS group</a>.
              </p>
			  
	      <p>
	      Previously, I did my bachelors at the <a href="https://en.hust.edu.vn/">Hanoi University of Science and Technology (HUST)</a>. <a href="https://www.youtube.com/watch?v=9IQPptJbO4M">My graduate internship</a> was done at <a href="https://www.mica.edu.vn/">International Research Institute MICA</a>, Hanoi, Vietnam et <a href="http://www.grenoblecognition.fr/index.php/le-pole/unites-contituantes/57-les-unites/172-agim-andrologie-gerontologie-inflammation-modelisation"> AGIM laboratory</a>, <a href="https://www.univ-grenoble-alpes.fr/english/">Université Grenoble Alpes</a>, Grenoble, France.
		      
	      </p>  
			  
              <p align=center>
		<a href="data/Huy_Hieu_PHAM_Doctoral_Thesis.pdf">Ph.D. Thesis</a> &nbsp/&nbsp
                <a href="data/Hieu-Pham-CV-2022.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=mXcFcNkAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
		<a href="https://github.com/huyhieupham/">GitHub</a> &nbsp/&nbsp
		<a href="https://www.linkedin.com/in/pham-huy-hieu-25615236/">LinkedIn</a> &nbsp/&nbsp
		<a href="https://twitter.com/Hieuhuy">Twitter</a>
              </p>
            </td>
            <td width="33%">
              <img src="images/huyhieupham_2_320x350.png">
            </td>
          </tr>
		
         </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research Interests</heading>
              <p>
                My research interests include Artificial Intelligence (AI), Machine Learning, Deep Learning, Computer Vision, especially their applications in Smart Healthcare, e.g. Medical Imaging Diagnosis, AI-based Computer-aided Diagnosis (AI-CAD), AI-assisted Diagnosis and Treatment, AI-assisted Disease Prevention and Risk Monitoring.

            </p>    
		    
		    <p style="color:red">I am looking for self-motivated PhD, Research Assisstants and Interns, who are interested in artificial intelligence for smart healthcare, computer vision, machine/deeep learning, and natural language processing. If you are interested in doing research with me, please send me an email (hieu.ph@vinuni.edu.) with your CV and transcripts. If you are a VinUni student and interested in conducting research, you can reach me via email for further dicussion.</p>

		   
		  </td>
          </tr>
	 </table>
	      
	  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>News</heading>
		    
			<p>
		    
		  <span>&#x25cf;</span> &nbsp; <b>[Sep. 2022]</b> &nbsp;  Take a short-term visit to the German Center for Neurodegenerative Diseases (<a href="https://www.dzne.de/">DZNE</a>), Bonn, and the German Research Center for Artificial Intelligence (<a href="DFKI">DFKI</a>), in order to explore new space for collaboration with <a href="https://www.dzne.de/forschung/forschungsbereiche/populationsforschung/forschungsgruppen/reuter/forschungsschwerpunkte/"> Prof. Martin Reuter</a> (Head of Image Analysis, DZNE; Assistant Professor of Radiology, Harvard Medical School) and <a href="https://www.isip.uni-luebeck.de/index.php?id=278"> Prof. Alfred Mertins</a> (Director of the Institute for Signal Processing, University of Lübeck). 
				
		  	</p>  
		    	    
		    
		    
		    
			<p>
		    
		  <span>&#x25cf;</span> &nbsp; <b>[Aug. 2022]</b> &nbsp;  I am looking for a PhD student working on <a href="https://smarthealth.vinuni.edu.vn/?careers=phd-studentship-ai-based-medical-image-analysis-for-early-detection-and-diagnosis"> AI-based Medical Image Analysis for Early Detection and Diagnosis </a>. This thesis shall be supervised by me, 
				Prof. <a href= "https://profiles.uts.edu.au/Qiang.Wu"> Qiang Wu</a>, and Prof. <a href="https://profiles.uts.edu.au/Min.Xu"> Min Xu</a> from <a href="https://www.uts.edu.au/"> University of Technology Sydney (UTS)</a>. Selected candidate will be provided full scholarships to conduct her/his research at VinUniversiy and UTS. 
		  	</p>  
		    
		    
		    
		    
		    
		    
		    
			<p>
		    
		  <span>&#x25cf;</span> &nbsp; <b>[Jul. 2022]</b> &nbsp;  I serve as a Program Committee (PC) Member for the <a href="https://aaai.org/Conferences/AAAI-23/"> Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI-23) </a>.
		  	</p>  
		    
			    
		   <p>
			<span>&#x25cf;</span> &nbsp; <b>[Jul. 2022]</b> &nbsp; Our paper "Deployment and validation of an AI system for detecting abnormal chest radiographs in clinical settings" is accepted by <a href="https://www.frontiersin.org/articles/10.3389/fdgth.2022.890759/full?&utm_source=Email_to_authors_&utm_medium=Email&utm_content=T1_11.5e1_author&utm_campaign=Email_publication&field=&journalName=Frontiers_in_Digital_Health&id=890759">Frontiers in Digital Health</a>.
		    	</p>      
		    
		    
		    
		   <p>
			<span>&#x25cf;</span> &nbsp; <b>[Jul. 2022]</b> &nbsp; Our paper "VinDr-CXR: An open dataset of chest X-rays with radiologist’s annotations" is accepted by <a href="https://www.nature.com/articles/s41597-022-01498-w?fbclid=IwAR0l1C6mFmV8v4Cq7tJFpqxGw1LH_eXrGnhi1AQ8mXucXCSkZkALVWXA4u4">Scientific Data (Nature, IF 9.051)</a>.
		    	</p>  
		    
		    
		     <p>
			<span>&#x25cf;</span> &nbsp; <b>[Jul. 2022]</b> &nbsp; <a href="https://smarthealth.vinuni.edu.vn/">VinUni-Illinois Smart Health Center (VISHC)</a> is officially launched. With 13,5 million USD in funding from Vingroup, VISHC will focus on interdisciplinary research in biotechnology and data science to develop affordable and accessible projects that can positively impact people’s health.	    
		    
		    	</p>  
		    
		 
		    
		    
		    
		    <p>
		    <span>&#x25cf;</span> &nbsp; <b>[Feb. 2022]</b> &nbsp; I serve as a Reviewer for European Conference on Computer Vision 2022 (<a href="https://eccv2022.ecva.net/">ECCV2022</a>) and the 25th International Conference on Medical Image
Computing and Computer Assisted Intervention (<a href="https://conferences.miccai.org/2022/en/">MICCAI2022</a>)
		    </p>
		    
		    <p>
			<span>&#x25cf;</span> &nbsp; <b>[Dec. 2021]</b> &nbsp; Our research team got $220K funding from <a href="https://vinif.org/">Vingroup Innovation Foundation - VinIF</a> to enhance medication safety. 
		    	</p>
		    
			<p>
			<span>&#x25cf;</span> &nbsp; <b>[Nov. 2021]</b> &nbsp; I gave a talk on <a href="/data/Explainable AI How human can trust AI - Hieu Pham VinUni.pdf">Explainablle AI</a>  at  <a href="https://ainow.bkai.ai/">AI Now: Research and Development</a> 2021 conference, organized by BK.AI (HUST) and Naver Corporation. 
		    	</p>
		    
			<p>
			<span>&#x25cf;</span> &nbsp; <b>[Nov. 2021]</b> &nbsp; I join VinUni as a Teaching Fellow at the College of Engineering and Computer Science and Research Fellow at VinUni-Illinois Smart Health Center (VISHC).
		    	</p>
		    <p>
			<span>&#x25cf;</span> &nbsp; <b>[Sep. 2021]</b> &nbsp; I serve as a reviewer for <a href="http://cvpr2022.thecvf.com/">IEEE/CVF Conference on Computer Vision and Pattern Recognition 2022 (CVPR2022)</a>.
		    </p>
		      
		    <p>
			<span>&#x25cf;</span> &nbsp; <b>[Aug. 2021]</b> &nbsp; We release VinDr-SpineXR: <a href="https://vindr.ai/datasets/spinexr">An open dataset for spinal lesions detection and classification from radiographs</a> on <a href="https://www.physionet.org/content/vindr-spinexr/1.0.0/">PhysioNet</a>. To the best of our knowledge, the VinDr-SpineXR is currently the largest dataset to date that provides radiologist’s bounding-box annotations for developing supervised-learning object detection algorithms. We believe that the dataset will serve as a benchmark dataset for accelerating the development and evaluation of new machine learning models for the spinal X-ray interpretation.
		    </p>
		    
		    <p>
			<span>&#x25cf;</span> &nbsp; <b>[Aug. 2021]</b> &nbsp; My article (in Vietnamese) on <a href="https://vjst.vn/vn/tin-tuc/5183/ung-dung-ai-trong-chan-doan-hinh-anh-y-khoa-tai-viet-nam.aspx">Application of AI in Medical Imaging: Some Recent Developments in Vietnam</a> has been published by Vietnam Journal of Science, Technology and Engineering (Tạp chí KH&CN Việt Nam).
		    </p>
		    
		    
		    <p>
			<span>&#x25cf;</span> &nbsp; <b>[Aug. 2021]</b> &nbsp; Two papers got accepted by <a href="https://sites.google.com/view/CVAMD2021/">ICCV Workshop 2021 on Computer Vision for Automated Medical Diagnosis</a>.
		    </p>		    
		    
		    
			<p>
			<span>&#x25cf;</span> &nbsp; <b>[June 2021]</b> &nbsp; One paper on "<a href="https://arxiv.org/pdf/2106.12930.pdf">A deep learning framework for spinal lesions detection and classification from radiographs</a>" got accepted by <a href="https://miccai2021.org/en/">International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2021)</a>.
		  	</p>		    
		    
		    
		    
		    <p>
			<span>&#x25cf;</span> &nbsp; <b>[May 2021]</b> &nbsp; Our new paper titled "<a href="https://openreview.net/pdf?id=oJi6xpSLdsj"> VinDr-RibCXR: A Benchmark Dataset for Automatic Segmentation and Labeling of Individual Ribs on Chest X-rays"</a> is accepted by <a href="https://2021.midl.io/">Medical Imaging with Deep Learning (MIDL 2021)</a>.
		    </p>
		    
		<p>
			<span>&#x25cf;</span> &nbsp; <b>[Apr. 2021]</b> &nbsp; I gave a talk on <a href="data/DS&AI-AI-in-Medical-Imaging-Hieu-Pham-VinBigdata.pdf">AI in Medical Imaging</a> at the <a href="https://soict.hust.edu.vn/summer-school/?fbclid=IwAR1-JJfbeaWVYmyE1kr9dBrqtkttpymNSk5OiKiWCzDbSBo_eZWhPr5vyzA">Summer School on Advances in DS&AI 2021 </a>.
		    </p>

		    
		    		<p>
			<span>&#x25cf;</span> &nbsp; <b>[Apr. 2021]</b> &nbsp; A new paper on AI for chest X-ray analysis is published on <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231221000953">Neurocomcomputing</a>.
		    </p>
		    
		    
		<p>
			<span>&#x25cf;</span> &nbsp; <b>[Mar. 2021]</b> &nbsp; I develop and deliver (with Prof. <a href="https://cs.illinois.edu/about/people/faculty/minhdo">Minh Do</a> and <a href="https://scholar.google.com/citations?user=xWYArRgAAAAJ&hl=en">Hieu Hoang - UIUC Ph.D. Student</a>) the <a href="https://vinuni.edu.vn/courses-of-instruction-fall-2020/free-choice-electives/">CECS1020 Introduction to Machine Learning</a> Course at <a href="https://vinuni.edu.vn/">VinUniversity</a>.
		    </p>
		    
		
		<p>
			<span>&#x25cf;</span> &nbsp; <b>[Feb. 2021]</b> &nbsp; I serve as a Reviewer for International Conference on Computer Vision (ICCV2021).
		    </p>
		    
		    
		<p>    
		   <span>&#x25cf;</span> &nbsp; <b>[Dec. 2019]</b> &nbsp;  I gave <a href="data/vinbid_chexpert_solution_presentation.pdf">a talk</a> on interpreting chest X-rays by exploiting disease dependencies and uncertainty labels.
		</p>    
		    
		    
		<p>    
		   <span>&#x25cf;</span> &nbsp; <b>[Sep. 2019]</b> &nbsp;  I just successfully defended my <a href="data/Huy_Hieu_PHAM_Doctoral_Thesis.pdf">Ph.D. thesis</a> at the Computer Science Research Institute of Toulouse (IRIT), France. The presentation is available <a href="data/PhD_Presentation_Final_Version_Hieu_Pham.pdf">here</a>. I will back to Hanoi, Vietnam and work as a Research Scientist in Computer Vision and Artificial Intelligence (AI) at the Vingroup Big Data Institute (VinBDI) starting from October 2019. My work focuses on applying the latest advances in Machine Learning & Deep Learning for Medical Imaging Analysis.
		</p>    
		    
		<p>    
		   <span>&#x25cf;</span> &nbsp; <b>[Aug. 2019]</b> &nbsp;  I gave an <a href="data/ICIAR_2019_Hieu_Pham.pdf">oral presentation</a> at the 16th International Conference on Image Analysis and Recognition (<a href="https://www.aimiconf.org/iciar19/">ICIAR'2019</a>).  
		</p>		    
		    
		<p>    
		   <span>&#x25cf;</span> &nbsp; <b>[July 2019]</b> &nbsp; In our recent study, we showed that a simple deep neural network is able to learn and predict 3D human poses from 2D keypoints obtained from RGB images. The full paper about this research is available on <a href="https://arxiv.org/pdf/1907.06968v1.pdf">arXiv</a>.   
		</p> 
	
		<p>    
		   <span>&#x25cf;</span> &nbsp; <b>[July 2019]</b> &nbsp;  I gave a <a href="data/Poster_SI_IRIT_17_July_2019.pdf">poster presentation</a> at the annual seminar of Toulouse Computer Science Research Institute (IRIT), France. The presentation was about training a deep learning neural network for predicting 3D human poses from their 2D keypoint detections on RGB images.   
		</p>
	      <p>
              		<span>&#x25cf;</span> &nbsp; <b>[May 2019]</b> &nbsp; My paper that was submitted to the <a href="https://www.aimiconf.org/iciar19/">16th International Conference on Image Analysis and Recognition</a> got accepted. I will be in Waterloo, Canada from August 27th to 29th, 2019 to give my talk about a new deep learning model for human action analysis.
              </p>
		    	    
	      <p>
		        <span>&#x25cf;</span> &nbsp; <b>[Apr. 2019]</b> &nbsp; Our new paper titled :"Spatio-Temporal Image Representation of 3D Skeletal Movements for View-Invariant Action Recognition with Deep Convolutional Neural Networks has been accepted for publication by the Special Issue "Deep Learning-Based Image Sensors". A preprint of the paper can be downloaded <a href="https://www.preprints.org/manuscript/201903.0086/v1">here</a>.
              </p>
		       
            
		<p> 
			<span>&#x25cf;</span> &nbsp; <b>[July 2018]</b> &nbsp; My new paper about improving ResNet architecture for human action recognition (HAR) with RGB-D data has been accepted with revision for publication by the <a href="http://digital-library.theiet.org/content/journals/iet-cvi"> IET Computer Vision Journal</a>.
			</p>
		 <p>
		<span>&#x25cf;</span> &nbsp; <b>[May 2018]</b> &nbsp; My paper titled: "Exploiting Inception-ResNet networks for human action recognition (HAR) from skeletal data" has been accepted for oral presentation at the <a href="https://2018.ieeeicip.org/">25th IEEE International Conference on Image Processing (ICIP 2018)</a>.
		</p>
		<p>
		<span>&#x25cf;</span> &nbsp; <b>[Jun. 2018 ]</b> &nbsp; My paper: "Exploiting deep residual networks for human action recognition from skeletal data" has been accepted for publication in the <a href="https://www.sciencedirect.com/science/article/pii/S1077314218300389"> Computer Vision and Image Understanding Journal</a>.
		</p> 
		<p>
		<span>&#x25cf;</span> &nbsp; <b>[Nov. 2017]</b> &nbsp; I am very honored to give a talk about Deep Learning for Image Recognition to the Ph.D. and Master's students at the Computer Science Department, <a href="https://www.uc3m.es/Home">University Carlos III of Madrid</a>. More information about this seminar can be found <a href="https://www.uc3m.es/ss/Satellite/Postgrado/es/TextoMixta/1371234989154"> here</a>.
		</p>
		<p>
		<span>&#x25cf;</span> &nbsp; <b>[May 2017]</b> &nbsp; My paper: "Learning and Recognizing Human Action from Skeleton Movement with Deep Residual Neural Networks " has been accepted for oral presentation at the <a href="https://communities.theiet.org/communities/events/item/122/75/15838"> 8th International Conference of Pattern Recognition Systems (ICPRS-17)</a>.		    
		</p>			    
            </td>
          </tr>
        </table>
	      
	      
	      
	<table width="95%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Publications</heading>	    
            </td>
	
	<tr onmouseout="loss_stop()" onmouseover="loss_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='loss_image'><img src='images/ICIAR_2019.png'></div>
                <img src='images/ICIAR_2019.png'>
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }
                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>		    
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.aimiconf.org/iciar19/">
                <papertitle>A Deep Learning Approach for Real-Time 3D Human Action Recognition from Skeletal Data</a>
	      <br> 
	      <font color="red"><strong>Conference Paper</strong></font>    
              <br>
              <strong>Huy Hieu Pham</strong>, 
	      <a href="https://scholar.google.fr/citations?user=yvLitLEAAAAJ&hl=fr">Houssam Salmane</a>,
	      <a href="https://www.researchgate.net/profile/Louahdi_Khoudour">Louahdi Khoudour</a>,
	      <a href="https://www.irit.fr/~Alain.Crouzil/">Alain Crouzil</a>,
	      <a href="https://www.researchgate.net/profile/Pablo_Zegers">Pablo Zegers</a>, and
	      <a href="https://www.uc3m.es/ss/Satellite/UC3MInstitucional/en/FormularioTextoDosColumnas/1371216239282/Very_experienced_fellow">Sergio A Velastin</a>
              <br>
              <em>The 16th International Conference on Image Analysis and Recognition</em>, ICIAR2019, August 27-29, 2019, Waterloo, Canada
              <br>
	      <p></p>
              <p>Building a real-time deep learning-based framework for skeleton-based human action recognition. Application to public transport monitoring.</p>
            </td>
          </tr>
	  </tr>
        </table>  
	      
	<table width="95%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>	  
	<tr onmouseout="loss_stop()" onmouseover="loss_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='loss_image'><img src='images/Sensors_2019.png'></div>
                <img src='images/Sensors_2019.png'>
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }
                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>		    
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.ncbi.nlm.nih.gov/pubmed/31022945">
                <papertitle>Spatio-Temporal Image Representation of 3D Skeletal Movements for View-Invariant Action Recognition with Deep Convolutional Neural Networks</a>
	      <br> 
	      <font color="red"><strong>Journal Paper</strong></font>    
              <br>
              <strong>Huy Hieu Pham</strong>, 
	      <a href="https://scholar.google.fr/citations?user=yvLitLEAAAAJ&hl=fr">Houssam Salmane</a>,
	      <a href="https://www.researchgate.net/profile/Louahdi_Khoudour">Louahdi Khoudour</a>,
	      <a href="https://www.irit.fr/~Alain.Crouzil/">Alain Crouzil</a>,
	      <a href="https://www.researchgate.net/profile/Pablo_Zegers">Pablo Zegers</a>, and
	      <a href="https://www.uc3m.es/ss/Satellite/UC3MInstitucional/en/FormularioTextoDosColumnas/1371216239282/Very_experienced_fellow">Sergio A Velastin</a>
              <br>
              <em>Deep Learning-Based Image Sensors, Intelligent Sensors</em>, Sensors 2019
              <br>
              <a href="https://www.preprints.org/manuscript/201903.0086/v1">Preprint</a> /
	      <a href=" https://doi.org/10.3390/s19081932">DOI</a> /    
              <a href="data/HieuPham_Sensors_2019.bib">BibTeX</a>
	       <p></p>
              <p> A new motion representation called Enhanced-SPMF for human action recognition in videos with deep neural networks.</p>
            </td>
          </tr>
	  </tr>
        </table>  
	 
	<table width="95%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
	<tr onmouseout="loss_stop()" onmouseover="loss_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='loss_image'><img src='images/IET_2018.png'></div>
                <img src='images/IET_2018.png'>
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }
                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>		    
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://digital-library.theiet.org/content/journals/10.1049/iet-cvi.2018.5014">
                <papertitle>Learning to Recognize 3D Human Action from A New Skeleton-based Representation Using Deep Convolutional Neural Networks</papertitle>
              </a>
	      <br> 
	      <font color="red"><strong>Journal Paper</strong></font>    
              <br>
              <strong>Huy Hieu Pham</strong>, 
	      <a href="https://www.researchgate.net/profile/Louahdi_Khoudour">Louahdi Khoudour</a>,
	      <a href="https://www.irit.fr/~Alain.Crouzil/">Alain Crouzil</a>,
	      <a href="https://www.researchgate.net/profile/Pablo_Zegers">Pablo Zegers</a>, and
	      <a href="https://www.uc3m.es/ss/Satellite/UC3MInstitucional/en/FormularioTextoDosColumnas/1371216239282/Very_experienced_fellow">Sergio A Velastin</a>
              <br>
              <em>IET Computer Vision</em>, IET 2018
              <br>
              <a href="https://arxiv.org/pdf/1812.10550.pdf">arXiv</a> /
	      <a href="https://doi.org/10.1049/iet-cvi.2018.5014">DOI</a> /    
              <a href="data/HieuPham_IET_2018.bib">BibTeX</a>
              <p></p>
              <p>Transforming 3D joint coordinates of the human body carried in skeleton sequences into RGB images for human action recognition in videos with deep neural networks.</p>
            </td>
          </tr>
	  </tr>
        </table>  
	  
	<table width="95%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
	<tr onmouseout="loss_stop()" onmouseover="loss_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='loss_image'><img src='images/ICIP_2018.png'></div>
                <img src='images/ICIP_2018.png'>
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }
                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>		    
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8451404">
                <papertitle>Skeletal Movement to Color Map: A Novel Representation for 3D Action Recognition with Inception Residual Networks</papertitle>
              </a>
	      <br> 
	      <font color="red"><strong>Conference Paper</strong></font>    
              <br>
              <strong>Huy Hieu Pham</strong>, 
	      <a href="https://www.researchgate.net/profile/Louahdi_Khoudour">Louahdi Khoudour</a>,
	      <a href="https://www.irit.fr/~Alain.Crouzil/">Alain Crouzil</a>,
	      <a href="https://www.researchgate.net/profile/Pablo_Zegers">Pablo Zegers</a>, and
	      <a href="https://www.uc3m.es/ss/Satellite/UC3MInstitucional/en/FormularioTextoDosColumnas/1371216239282/Very_experienced_fellow">Sergio A Velastin</a>
              <br>
              <em>The 25th IEEE International Conference on Image Processing</em>, ICIP2018, October 7-10, 2018, Athens, Greece
              <br>
              <a href="https://arxiv.org/pdf/1807.07033.pdf">arXiv</a> /
	      <a href="https://doi.org/10.1109/ICIP.2018.8451404">DOI</a> /    
              <a href="data/HieuPham_ICIP_2018.bib">BibTeX</a>
	      <p></p>
              <p>Proposing a new 3D skeleton-based representation, namely, SPMF (Skeleton Pose-Motion Feature) for video-based human action recogntion with depth sensors.</p>
            </td>
          </tr>
	  </tr>
        </table>  
		  
	<table width="95%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
	<tr onmouseout="loss_stop()" onmouseover="loss_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='loss_image'><img src='images/CVIU_figure.png'></div>
                <img src='images/CVIU_figure.png'>
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }
                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>		    
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.sciencedirect.com/science/article/pii/S1077314218300389">
                <papertitle>Exploiting Deep Residual Networks for Human Action Recognition from Skeletal Data</papertitle>
              </a>
	      <br> 
	      <font color="red"><strong>Journal Paper</strong></font>    
              <br>
              <strong>Huy Hieu Pham</strong>, 
	      <a href="https://www.researchgate.net/profile/Louahdi_Khoudour">Louahdi Khoudour</a>,
	      <a href="https://www.irit.fr/~Alain.Crouzil/">Alain Crouzil</a>,
	      <a href="https://www.researchgate.net/profile/Pablo_Zegers">Pablo Zegers</a>, and
	      <a href="https://www.uc3m.es/ss/Satellite/UC3MInstitucional/en/FormularioTextoDosColumnas/1371216239282/Very_experienced_fellow">Sergio A Velastin</a>
              <br>
              <em>Computer Vision and Image Understanding</em>, CVIU 2018
              <br>
              <a href="https://arxiv.org/pdf/1803.07781.pdf">arXiv</a> /
	      <a href="https://doi.org/10.1016/j.cviu.2018.03.003">DOI</a> /    
	      <a href="https://github.com/huyhieupham/Improved-ResNet-Action-Recognition-Skeletal-Data">Code</a> /
              <a href="data/HieuPham_CVIU_2018.bib">BibTeX</a>
	      <p></p>
              <p>Investigating and applying deep ResNets for human action recognition using skeletal data provided by depth sensors.</p>
            </td>
          </tr>
	  </tr>
        </table>  
		  
	<table width="95%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
	<tr onmouseout="loss_stop()" onmouseover="loss_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='loss_image'><img src='images/DefautJENv1.png'></div>
                <img src='images/DefautJENv1.png'>
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }
                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>		    
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/article/10.1007/s10921-017-0453-1">
                <papertitle>3D Point Cloud Analysis for Detection and Characterization of Defects on Airplane Exterior Surface</papertitle>
              </a>
	      <br> 
	      <font color="red"><strong>Journal Paper</strong></font>    
              <br>
              Igor Jovančević, <strong>Huy Hieu Pham</strong>, Jean-José Orteu, Rémi Gilblas, Jacques Harvent, Xavier Maurice, and Ludovic Brèthes
              <br>
              <em>Journal of Nondestructive Evaluation</em>, JNE 2017
              <br>
              <a href="https://hal-mines-albi.archives-ouvertes.fr/hal-01622056/document">Full-text PDF</a> /
	      <a href="https://doi.org/10.1007/s10921-017-0453-1">DOI</a> /    
              <a href="data/Jovancevic2017JNE.bib">BibTeX</a>
              <p></p>
              <p>A novel automatic vision-based inspection system that is capable of detecting and characterizing defects on an airplane exterior surface.</p>
            </td>
          </tr>
	  </tr>
        </table>  
		
	<table width="95%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr> 	  
	   <tr onmouseout="loss_stop()" onmouseover="loss_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='loss_image'><img src='images/Nuage.png'></div>
                <img src='images/Nuage.png'>
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }
                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>		    
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://hal.archives-ouvertes.fr/hal-01660998/">
                <papertitle>Détection et Caractérisation de Défauts de Surface par Analyse des Nuages de Points 3D Fournis par un Scanner</papertitle>
              </a>
	      <br> 
	      <font color="red"><strong>Journal Paper</strong></font>    
              <br>
              Igor Jovančević, <strong>Huy Hieu Pham</strong>, Jean-José Orteu, Rémi Gilblas, Jacques Harvent, Xavier Maurice, and Ludovic Brèthes
              <br>
              <em>Journal of Sensors</em>, 2016
              <br>
              <a href="https://hal.archives-ouvertes.fr/hal-01660998/document">Full-text PDF</a> /
              <a href="data/jovancevic:hal2017.bib">BibTeX</a>
              <p></p>
              <p>A system that is able to detect obstacles in indoor environment based on Kinect sensor and 3D-image processing.</p>
            </td>
          </tr>
	  </tr>
        </table>
	  
	<table width="95%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr> 
	<tr onmouseout="loss_stop()" onmouseover="loss_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='loss_image'><img src='images/ResNet.png'></div>
                <img src='images/Kinect-Joint.png'>
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }
                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>		    
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://digital-library.theiet.org/content/conferences/10.1049/cp.2017.0154">
                <papertitle>Learning and Recognizing Human Action from Skeleton Movement with Deep Residual Neural Networks</papertitle>
              </a>
	      <br> 
	      <font color="red"><strong>Conference Paper</strong></font>
              <br>
              <strong>Huy Hieu Pham</strong>, 
	      <a href="https://www.researchgate.net/profile/Louahdi_Khoudour">Louahdi Khoudour</a>,
	      <a href="https://www.irit.fr/~Alain.Crouzil/">Alain Crouzil</a>,
	      <a href="https://www.researchgate.net/profile/Pablo_Zegers">Pablo Zegers</a>, and
	      <a href="https://www.uc3m.es/ss/Satellite/UC3MInstitucional/en/FormularioTextoDosColumnas/1371216239282/Very_experienced_fellow">Sergio A Velastin</a>
              <br>
              <em>The 8th International Conference of Pattern Recognition Systems</em>, ICPRS2017, July 12-13, 2017, Madrid, Spain
              <br>
              <a href="https://arxiv.org/pdf/1803.07780.pdf">arXiv</a> /
	      <a href="https://doi.org/10.1049/cp.2017.0154">DOI</a> /
              <a href="data/HieuPhamCVPRS2017.bib">BibTeX</a>
              <p></p>
              <p>Training Deep Residual Neural Networks to learn and recognize human action from skeleton data provided by Kinect sensor.</p>
            </td>
          </tr>
	   </tr>
        </table>
	  
	<table width="95%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>	
	<tr onmouseout="loss_stop()" onmouseover="loss_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='loss_image'><img src='images/obtacle1.png'></div>
                <img src='images/obtacle2.png'>
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }
                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>		    
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.hindawi.com/journals/js/2016/3754918/abs/">
                <papertitle>Real-time Obstacle Detection System in Indoor Environment for the Visually Impaired Using Microsoft Kinect Sensor</papertitle>
              </a>
	      <br> 
	      <font color="red"><strong>Journal Paper</strong></font>
              <br>
              <strong>Huy Hieu Pham</strong>, 
	      <a href="https://www.mica.edu.vn/perso/Le-Thi-Lan/">Thi Lan Le</a>, and
	      <a href="https://www.omicsonline.org/editor-profile/Nicolas_Vuillerme/">Nicolas Vuillerme</a>
              <br>
              <em>Journal of Sensors</em>, 2016 
		    
              <br>
              <a href="http://downloads.hindawi.com/journals/js/2016/3754918.pdf">Full-text PDF</a> /
              <a href="https://www.hindawi.com/journals/js/2016/3754918/">Full-text HTML </a> /
	      <a href="http://dx.doi.org/10.1155/2016/3754918/>DOI</a> /
              <a href="https://www.youtube.com/watch?v=9IQPptJbO4M">Video</a> /
              <a href="data/HieuPhamSensor2016.bib">BibTeX</a>
              <p></p>
              <p>A system that is able to detect obstacles in indoor environment based on Kinect sensor and 3D-image processing.</p>
            </td>
          </tr>
						   
          </tr>
		
						   
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Teaching</heading>
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Instructor</b>, College of Engineering & Computer Science (CECS), VinUniversity. <br>
				&nbsp; &nbsp; &nbsp; <b> Course:</b> <i> "Introduction to Programing - CECS-COMP1010 (Fall 2021-2022)"</i>, with Prof. <a href="https://vinuni.edu.vn/people/kok-seng-wong/">Kok-Seng Wong</a>
		</p>					    
				
					    
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Instructor</b>, College of Engineering & Computer Science (CECS), VinUniversity. <br>
				&nbsp; &nbsp; &nbsp; <b> Course:</b> <i> "Introduction to Machine Learning - CECS-1020 (Spring 2021-2022)"</i>, with Prof. <a href="https://vinuni.edu.vn/people/minh-do/">Minh Do</a>
		</p>					    
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Guest Lecturer</b>, University Carlos III of Madrid, Spain. <br>
		                  &nbsp; &nbsp; &nbsp;  <b> Course:</b> 	<i>"An introduction to Deep Learning for Image and Video Interpretation"</i>, (Fall 2017-2018).
		</p>						    
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Teaching Assistant</b>, University of Toulouse, France. <br>
					&nbsp; &nbsp; &nbsp;  <b> Course:</b> <i> "Introduction to Programming and Algorithms in Python"</i>, (Fall 2018-2019).															
		</p>						    
            </td>
          </tr>
	 </table>						   
						   
			   
						   
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Professional Activities</heading>
	
					    	
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Visiting Scholar</b>,  German Research Center for Artificial Intelligence (<a href="https://kse2022.tbd.edu.vn/">DFKI</a>), University of Lübeck, 2022.
		</p>				    
			
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Visiting Scholar</b>,  German Center for Neurodegenerative Diseases (<a href="https://kse2022.tbd.edu.vn/">DZNE</a>), 2022. 
		</p>				    
					    
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>,  IEEE International Conference on Knowledge and Systems Engineering (<a href="https://kse2022.tbd.edu.vn/">IEEE KSE 2022</a>) 
		</p>
		
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>,  IEEE Journal of Selected Topics in Signal Processing (<a href="https://signalprocessingsociety.org/publications-resources/ieee-journal-selected-topics-signal-processing/about-jstsp">JSTSP</a>) 
		</p>
					
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>,  European Conference on Computer Vision (<a href="https://eccv2022.ecva.net/">ECCV 2022</a>) 
		</p>
					    				    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>,  International Conference on Medical Image Computing and Computer Assisted Intervention (<a href="https://conferences.miccai.org/2022/en/">MICCAI 2022</a>) 
		</p>
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>, IEEE Journal of Biomedical and Health Informatics (<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221020">JBHI</a>) 
		</p>
					    
					    
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>, Journal of Electronic Imaging (<a href="https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging?SSO=1">JEI</a>) 
		</p>					    
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>, IET Computer Vision Journal (<a href="https://digital-library.theiet.org/content/journals/iet-cvi">IET-CVI</a>)
		</p>						    
					    
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>, International Conference on Computer Vision (<a href="http://iccv2021.thecvf.com/home">ICCV 2021</a>)
		</p>
			
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>, IEEE/CVF Conference on Computer Vision and Pattern Recognition 2022 (<a href="https://cvpr2022.thecvf.com/">CVPR2022</a>) 
		</p>			

		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>, Nature <a href="https://www.nature.com/srep/">Scientific Reports</a>
		</p>
		
		<p>    
		   <span>&#x25cf;</span> &nbsp;  <b>Program Commitee</b>, International Conference on Multimedia Analysis and Pattern Recognition (<a href="https://mapr.uit.edu.vn/program-committee">MAPR</a>)	   
		</p>
					    
					    			    
					    
					    
            </td>
          </tr>
	 </table>					   
						   
					    
					    
					   			    
					    
        </table>
	      
        <table width="100%" align="center" border="0" cellpadding="20"> 
	
            
              <p>
                
                <br>
                <br>
                
                <br>
                <br>
              </p>
            </td>
        
								      

								      
							      
								      
								      
								      
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
                  Thanks <a href="https://jonbarron.info/">Jon Barron</a> for his awesome open source code.
       
                  </font>
              </p>
            </td>
          </tr>
        </table>	
	      

		
        
         <!–– Please delete this script if you use this HTML. ––>
        <script type="text/javascript">
          var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
        </script>
        <script type="text/javascript">
          try {
            var pageTracker = _gat._getTracker("UA-7580334-1");
            pageTracker._trackPageview();
          } catch (err) {}
        </script>
        </td>
    </tr> 
  </table>
</body>
</html>		
				     
							     
